{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team - LogisticRegression\n",
    "Tobias Vogt, Michael Lappert, Tobias Bischof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "As part of the \"Data Science\" module, the class was given the task of making a prediction for the price of used cars. The aim is to make as accurate a prediction as possible for the price in a Kaggle competition. The participants should learn how to approach such a project by means of a practical example. To apply the theoretical material from the class. This work includes a Jupyter notebook and a presentation of the results. The work will be solved in groups of three or four. This work is limited to the train and a test file of the corresponding Kaggle competition. However, numerous functions as well as commands from the internet were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Libraries\n",
    "This chapter covers all libraries used in this work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_object_dtype, is_numeric_dtype\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "#importing data viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# to display visuals in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#ml \n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.base import clone \n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set_palette(sns.color_palette(\"muted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions\n",
    "Functions use throughout the notebook are defined here for a better reader experience afterward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopted from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-1.ipynb\n",
    "def missing_values_table(df):\n",
    "    '''\n",
    "    Utility functi# 2) Libraries\n",
    "\n",
    "\n",
    "on to calculate the missing values in absolute and percent values.\n",
    "    '''\n",
    "    mis_val = df.isnull().sum()\n",
    "\n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent],\n",
    "                              axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "\n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = (mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1))\n",
    "\n",
    "    # Print some summary information\n",
    "    print(\"The selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "          \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "\n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "# from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/tree/master/notebooks\n",
    "def plot_distribution(df, target, column_values, column_name):\n",
    "    # funtion to print distribution of a continuous variable\n",
    "    #Â for categorical data\n",
    "\n",
    "    for value in column_values:\n",
    "        subset = df[\n",
    "            df[column_name] == value]\n",
    "        g = sns.kdeplot(subset[target],\n",
    "                        label=value,\n",
    "                        linewidth=3)\n",
    "\n",
    "    # set title, legends and labels\n",
    "    plt.ylabel(\"Density\",\n",
    "               size=14)\n",
    "    plt.xlabel(\"{}\".format(target),\n",
    "               size=14)\n",
    "    plt.title(\"Distribution of {} per {}\"\n",
    "              .format(target, column_name),\n",
    "              size=16)\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "# Adopted from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-1.ipynb\n",
    "def plot_histogram(df, column, b=None):\n",
    "    '''\n",
    "    function to print histogram\n",
    "    with mean and median\n",
    "    using distplot\n",
    "    '''\n",
    "\n",
    "    # set the histogram, mean and median\n",
    "    g = sns.distplot(df[column],\n",
    "                     kde=False,\n",
    "                     bins=b)\n",
    "    plt.axvline(x=df[column].mean(),\n",
    "                linewidth=3,\n",
    "                color='g',\n",
    "                label=\"mean\",\n",
    "                alpha=0.5)\n",
    "    plt.axvline(x=df[column].median(),\n",
    "                linewidth=3,\n",
    "                color='y',\n",
    "                label=\"median\",\n",
    "                alpha=0.5)\n",
    "\n",
    "    # set title, legends and labels\n",
    "    plt.xlabel(\"{}\".format(column),\n",
    "               size=14)\n",
    "    plt.ylabel(\"Count\",\n",
    "               size=14)\n",
    "    plt.title(\"Distribution of {}\".format(column),\n",
    "              size=16)\n",
    "    plt.legend([\"mean\", \"median\"])\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "# From dslectures.core\n",
    "def convert_strings_to_categories(df):\n",
    "    \"\"\"\n",
    "    A utility function to convert all string columns to Categorical data type.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if is_object_dtype(df[col]):\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "\n",
    "# Adopted from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-1.ipynb\n",
    "def filling_df(df):\n",
    "    '''\n",
    "    function converts strings to categories and\n",
    "    categories to numbers\n",
    "    and imputes for missing values the median.\n",
    "    '''    \n",
    "    # converting strings to categories\n",
    "    convert_strings_to_categories(df)\n",
    "\n",
    "    # Converting categories to numbers\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    # Imputing the median to the missing values\n",
    "    median = df.median()\n",
    "    df.fillna(median, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function takes the datepart and creates new columns with information gained out of the date\n",
    "# (originally from https://course18.fast.ai/lessonsml1/lesson1.html)\n",
    "def add_datepart(df, fldname, drop=True):\n",
    "    '''\n",
    "    Extracts datepart into several new more useful features\n",
    "    '''\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, \n",
    "                                     infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', \n",
    "            'Dayofyear', 'Is_month_end', 'Is_month_start', \n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', \n",
    "            'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "        \n",
    "\n",
    "#Function of lesson05 of ds\n",
    "def print_scores(fitted_model):\n",
    "    \"\"\"Generates RMSE and R^2 scores from fitted Random Forest model.\"\"\"\n",
    "\n",
    "    yhat_train = fitted_model.predict(X_train)\n",
    "    R2_train = fitted_model.score(X_train, y_train)\n",
    "    yhat_valid = fitted_model.predict(X_valid)\n",
    "    R2_valid = fitted_model.score(X_valid, y_valid)\n",
    "\n",
    "    scores = {\n",
    "        \"RMSE on train:\": rmse(y_train, yhat_train),\n",
    "        \"R^2 on train:\": R2_train,\n",
    "        \"RMSE on valid:\": rmse(y_valid, yhat_valid),\n",
    "        \"R^2 on valid:\": R2_valid,\n",
    "    }\n",
    "    if hasattr(fitted_model, \"oob_score_\"):\n",
    "        scores[\"OOB R^2:\"] = fitted_model.oob_score_\n",
    "\n",
    "    for score_name, score_value in scores.items():\n",
    "        print(score_name, round(score_value, 3))\n",
    "        \n",
    "\n",
    "#Function from dslecture.core\n",
    "def rmse(y, yhat):\n",
    "    \"\"\"A utility function to calculate the Root Mean Square Error (RMSE).\n",
    "    \n",
    "    Args:\n",
    "        y (array): Actual values for target.\n",
    "        yhat (array): Predicted values for target.\n",
    "        \n",
    "    Returns:\n",
    "        rmse (double): The RMSE.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "# https://lewtun.github.io/dslectures/lesson09_overfitting/\n",
    "def plot_fitting_graph(x, metric_train, metric_valid, metric_name='metric', xlabel='x', yscale='linear'):\n",
    "    plt.plot(x, metric_train, label='train')\n",
    "    plt.plot(x, metric_valid, label='valid')\n",
    "    plt.yscale(yscale)\n",
    "    plt.title('Fitting graph')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the data\n",
    "Since we all run our notebooks locally. we have stored all data paths of the group members in our master document. This makes it easier to work in one document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('your_path')\n",
    "test = pd.read_csv('your_path')\n",
    "sample_submission = pd.read_csv('your_path')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With these first comands we got a rough overview of the two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} rows and {} columns in the train dataset.\"\n",
    "      .format(train.shape[0], train.shape[1]))\n",
    "\n",
    "print(\"There are {} rows and {} columns in the test dataset.\"\n",
    "      .format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Explore the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the data for exploration.\n",
    "train_ex = train.copy()\n",
    "test_ex = test.copy()\n",
    "train_ex.shape, test_ex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Study each attribute and its characteristics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter of the notebook is looked at the following points:\n",
    "- Name\n",
    "- Type (categorical, int/float, bounded/unbounded, text, structered, etc.)\n",
    "- % of missing values\n",
    "- Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "- Possibly useful for the task?\n",
    "- Type of distribution (Gaussian, uniform, logarithmic, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if every carId belongs to one entry and hence are unique\n",
    "len(train_ex) == train_ex.carId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the first five row of the dataset to get an impretion how the dataset looks like\n",
    "train_ex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at 10 randomly chosen rows to get an further impression and to see if something strange appears.\n",
    "train_ex.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some first explanations about the features and the target:\n",
    "* **price:** Target value, price of the car\n",
    "* **carId:** Every row and therfore every entry has his own ID\n",
    "* **dateCrawled:** Date when data was downloaded\n",
    "* **name:** Some description about the car added to the portal\n",
    "* **seller:** Wheter the seller of the corresponding car is `privat` or `gewerblich`\n",
    "* **offerType:** Wheter the seller is looking or offering for a car\n",
    "* **abtest:** _not known yet_\n",
    "* **vehicleType:** What kind of car os offered\n",
    "* **yearOfRegistration:** When the car was registered first\n",
    "* **gearbox:** Wheter the gearbox is `manuell`or `automatik`\n",
    "* **powerPS:** Amount of horsepower of the car\n",
    "* **model:** Which model is the car\n",
    "* **kilometer:** How many kilometer the car is already driven\n",
    "* **monthOfRegistration:** In which month of the Registrationyear the car was registered\n",
    "* **fuelType:** Which type of fuel the car uses\n",
    "* **brand:** Brand of the car\n",
    "* **notRepairedDamage:** If the car has some damage at the time selling\n",
    "* **dateCreated:** When the entry of the car was created on the portal\n",
    "* **nrOfPictures:** Number of pictures of the car in the inserat\n",
    "* **postalCode:** Postalcode of the city where the car is at\n",
    "* **lastSeen:** Last date when was looked at the car before it was sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The majority of the features in the dataset are strings. Both datasets have some missing values.\n",
    "# The strings we have to convert into numerical values and the missing values we have to handle by either\n",
    "# dropping or filling them to work with the datasets in the machine learning models.\n",
    "train_ex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the missing values are from string features.\n",
    "missing_values_table(train_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots from lecture 2\n",
    "# Plotting the percantage of missing values\n",
    "percentage_null = (train_ex.isnull().sum()/len(train_ex)).sort_values(ascending=False)\n",
    "percentage_null = percentage_null[percentage_null > 0]\n",
    "sns.barplot(percentage_null.values, percentage_null.index, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Exploring the object features first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-1.ipynb\n",
    "# Exploring the number of unique label of the object features\n",
    "object_columns = (train_ex\n",
    "                 .select_dtypes(include='object')\n",
    "                 .columns)\n",
    "\n",
    "for column in object_columns:\n",
    "    print(\"{} has {} unique values.\"\n",
    "          .format(column,\n",
    "                 train_ex[column]\n",
    "                 .nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High cardinality features (> 300 values):**\n",
    "\n",
    "* dateCrawled\n",
    "* name\n",
    "* lastSeen\n",
    "\n",
    "**Moderate cardinality features (> 30 values):**\n",
    "\n",
    "* model\n",
    "* brand\n",
    "* dateCreated\n",
    "\n",
    "**Low cardinality features (< 10 values):**\n",
    "\n",
    "* seller\n",
    "* offerType\n",
    "* abtest\n",
    "* vehicleType\n",
    "* gearbox\n",
    "* fuelType\n",
    "* notRepairedDamage\n",
    "\n",
    "There seem to be some identical name's. This seems strange because the name's can be typed in individually and it is expected that every person writes at least a slighty different description.\n",
    "There are more fuelTypes than just the most common ones like Diesel or Benzin.\n",
    "The dateCreated has a relatively small number compared to the number of entries in the dataset.\n",
    "\n",
    "In the following it is looked at each object feature's unique values (excluding model and dateCreated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Because it makes sense to use the price for some plots, it is looked first to this feature.\n",
    "# Price reaches up to 2e9. This is really unrealistic. Checking some carselling pages the maximum price is set to 5e6.\n",
    "# By far the majority of prices lay around 0. \n",
    "train_ex = train_ex.loc[(train_ex.price < 40000)]\n",
    "train_ex = train_ex.loc[(train_ex.price > 0)]\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_ex, 'price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brands reach from cheaper brands as 'kia', 'hyundai' or 'daewoo' to exclusive brands as 'jaguar' or 'porsche'.\n",
    "# There is also some aggregation of cars called 'sonstige_autos'\n",
    "# Volkswagen is by far the most common brand in the dataset. audi, bmw, mercedes benz and opel have the second highest \n",
    "# entries more or less equally distributed\n",
    "brands = (train_ex.brand.value_counts())\n",
    "\n",
    "print(brands.index)\n",
    "\n",
    "brands.plot(kind='bar', fontsize=15)\n",
    "plt.title('Counts per brand', fontsize=25)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq1_brands = list(\n",
    "    brands[\n",
    "        brands.values > 4000]\n",
    "    .index)\n",
    "\n",
    "freq2_brands = list(\n",
    "    brands[\n",
    "        brands.values < 600]\n",
    "    .index)\n",
    "\n",
    "# It can be observed that the 10 most fequent brands have a similar distribution, whereas the fewest frequent brands\n",
    "# show an inhomogen distribution. The fewest frequent brands have higher prices in general. Both plots show a\n",
    "# 'right-skewed' distribution in tendency.\n",
    "\n",
    "# distribution of the price per brand\n",
    "figsize(20, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# plot points distribution for 10 most frequent brands\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq1_brands, \"brand\");\n",
    "\n",
    "# plot points distribution for 11 fewest frequent brands\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq2_brands, \"brand\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are almost none of the entries 'gewerblich'.\n",
    "sellers = train_ex.seller.value_counts()\n",
    "\n",
    "print(sellers)\n",
    "\n",
    "sellers.plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts per seller', fontsize=25)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are not just 'Gesuch' but also 'Angebot'. By far the most etries are 'Angebot'.\n",
    "offerTypes = train_ex.offerType.value_counts()\n",
    "\n",
    "print(offerTypes)\n",
    "\n",
    "offerTypes.plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts per offerType', fontsize=25)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some seem to look for a car and are willing to pay quite some money for the searched car.\n",
    "freq_offerTypes = list(\n",
    "    offerTypes[\n",
    "        offerTypes.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_offerTypes, \"offerType\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abtests = train_ex.abtest.value_counts()\n",
    "\n",
    "abtests.plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts of abtest', fontsize=25)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It could not exactly found out what the abtest is. But looking at the price distributions of its to labels there\n",
    "# seems to be no difference and therfore it was not longer looked at.\n",
    "freq_abtests = list(\n",
    "    abtests[\n",
    "        abtests.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_abtests, \"abtest\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beside the expected vehicleTypes there are also some aggregated in 'andere'. By far the most frequent vehicleTypes\n",
    "# are limousine, kleinwagen and kombi.\n",
    "vehicleTypes = train_ex.vehicleType.value_counts()\n",
    "\n",
    "vehicleTypes.plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts per vehicleType', fontsize=25)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suv's seem to have the widest range of high prices whereas kleinwagen seem to be the cheapest ones.\n",
    "freq_vehicleTypes = list(\n",
    "    vehicleTypes[\n",
    "        vehicleTypes.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_vehicleTypes, \"vehicleType\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most cars have a manuell gearbox.\n",
    "gearboxes = train_ex.gearbox.value_counts()\n",
    "\n",
    "gearboxes.plot(kind='bar', fontsize=20)\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.title('Counts per gearbox', fontsize=25);\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It lookes like people are paying more for automatik gearboxed cars.\n",
    "freq_gearboxes = list(\n",
    "    gearboxes[\n",
    "        gearboxes.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_gearboxes, \"gearbox\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benzin and diesel seem to be the by far most common fuelTypes.\n",
    "fuelTypes = train_ex.fuelType.value_counts()\n",
    "\n",
    "print(fuelTypes);\n",
    "\n",
    "train_ex.fuelType.value_counts().plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts per fuelType', fontsize=25);\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xlabel('fuelType', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars with the fuelType hybrid seem to be the most ecpensive ones. Cars with the benzin and andere seem to be the\n",
    "# cheapest ones. Benzin compared with diesel (the two by far most common fuelTypes) is cheaper.\n",
    "freq_fuelTypes = list(\n",
    "    fuelTypes[\n",
    "        fuelTypes.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_fuelTypes, \"fuelType\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the kilometers and the corresponding prices, it could be interpreted, that for cars with fuelType elektro,\n",
    "# people pay less although they have less kilometer then hybrid.\n",
    "train_ex.groupby('fuelType')['kilometer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex.groupby('fuelType')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be observed, that hybrid is more expensive (even the most expensive) than elektro and diesel is more\n",
    "# expensive than benzin. \n",
    "train_ex.groupby('fuelType')['price'].mean().sort_values().plot(kind='bar', fontsize=20)\n",
    "plt.title('Mean price per fuelType', fontsize=25);\n",
    "plt.ylabel('Mean price', fontsize=20);\n",
    "plt.xlabel('fuelType', fontsize=20)\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seem to be not many car which has a notRepairedDamage. But one could think, that the ones who do have one,\n",
    "# rather do not post anything than declaring it.\n",
    "notRepairedDamages = train_ex.notRepairedDamage.value_counts()\n",
    "\n",
    "train_ex.notRepairedDamage.value_counts().plot(kind='bar', fontsize=20)\n",
    "plt.title('Counts per notRepairedDamage', fontsize=25);\n",
    "plt.ylabel('Counts', fontsize=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As expected is less paid for cars with a notRepairedDamage.\n",
    "freq_notRepairedDamages = list(\n",
    "    notRepairedDamages[\n",
    "        notRepairedDamages.values > 0]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_notRepairedDamages, \"notRepairedDamage\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following names are the 10 most listed in the dataset.\n",
    "names = train_ex.name.value_counts()\n",
    "\n",
    "freq_names = list(\n",
    "    names[\n",
    "        names.values > 270]\n",
    "    .index)\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_names, \"name\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_ex.model.value_counts()\n",
    "\n",
    "freq1_models = list(\n",
    "    models[\n",
    "        models.values > 5000]\n",
    "    .index)\n",
    "\n",
    "freq2_models = list(\n",
    "    models[\n",
    "        models.values < 15]\n",
    "    .index)\n",
    "\n",
    "# It can be observed that the 10 most fequent models have a similar distribution, whereas the fewest frequent models\n",
    "# show an inhomogen distribution. The fewest frequent models have higher prices in general.\n",
    "\n",
    "# distribution of the price per model\n",
    "figsize(20, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# plot points distribution for 10 most frequent models\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq1_models, \"model\");\n",
    "\n",
    "# plot points distribution for 11 fewest frequent models\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq2_models, \"model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Exploring the numerical features\n",
    "The values which are unrealistic are cleaned right away in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# powerPS has values up to 20000 which seems to be really unrealistic. The maximum powerPS is set to 500. A lot of \n",
    "# the cars seem to have 0 powerPS which seems strange and are filtered out. These values are partly from carpieces.\n",
    "# The distribution seems to be ok.\n",
    "train_ex = train_ex.loc[(train_ex.powerPS < 500)]\n",
    "train_ex = train_ex.loc[(train_ex.powerPS > 0)]\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_ex, 'powerPS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the yearOfRegistration reaches from 0 up to 10000 which is also unrealistic. The timehorizon is set from 1930 to 2017.\n",
    "# In 2016 is the latest date of lastSeen in this dataset.\n",
    "# The distribution seems to be quite ok.\n",
    "train_ex = train_ex.loc[(train_ex.yearOfRegistration<2017)]\n",
    "train_ex = train_ex.loc[(train_ex.yearOfRegistration>1930)]\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_ex, 'yearOfRegistration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seems to be a limitation of 150000 kilometer on the homepage input parameters where the cars are sold. Therefore\n",
    "# it seems likely that there are cars that have more than 150000 kilometers. One has to consider this when looking\n",
    "# at cars with kilometers of 150000. Means they could possibly have higher kilometervalues. There seems also to be a\n",
    "# little peak at the down side of kilometer values.\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_ex, 'kilometer');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Comparing the prices of the cars with different kilometervalues, it seems that there is something going on with the \n",
    "# prices of the cars which have 5000 kilometer. Comparing the mean and median values reveals that there must be big\n",
    "# differences in the prices because the mean is significantly higher than the median. One has to take this into \n",
    "# account in the further feature engineering part. It has to be said though, that the mean price is in every case\n",
    "# higher than the median price in this case.\n",
    "\n",
    "# distribution of the price per model\n",
    "figsize(20, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# plot points distribution for 10 most frequent models\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Median price per kilometer', fontsize=20)\n",
    "train_ex.groupby('kilometer')['price'].median().plot(kind='bar', fontsize=20);\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# plot points distribution for 11 fewest frequent models\n",
    "plt.subplot(1, 2, 2);\n",
    "plt.title('Mean price per kilometer', fontsize=20);\n",
    "train_ex.groupby('kilometer')['price'].mean().plot(kind='bar', fontsize=20);\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is assumed that the high prices of old cars are due to rare oldtimers. Which would be a reasonable explanation.\n",
    "train_ex.groupby('yearOfRegistration')['price'].median().plot(kind='bar', fontsize=20);\n",
    "plt.title('Mean price per yearOfRegistration', fontsize=25);\n",
    "plt.ylabel('price', fontsize=20);\n",
    "plt.xlabel('yearOfRegistration', fontsize=20);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postalCodes = (train_ex.postalCode.value_counts())\n",
    "\n",
    "freq_postalCodes = list(\n",
    "    postalCodes[\n",
    "        postalCodes.values > 160]\n",
    "    .index)\n",
    "\n",
    "# It can be observed, that the two most frequent postalcodes are 10115 and 65428. Consulting Google with this postalCodes\n",
    "# of Germany, it can be found, that the first postalCode belongs to Berlin-Mitte. This is a 'trendy' and exclusive\n",
    "# and therefore expensive city part of Berlin. It is assumed, at the people who live there also own more expensive cars.\n",
    "# This can be observed in the datadistribution as well.\n",
    "# The second postalCode is from RÃ¼sselsheim am Main. It got famous because the automotive brand opel produced there in the\n",
    "# beginnig their cars. Furthermore it belongs to Frankfurt, the 'money-city' of Germany. Also here it is assumed, that the\n",
    "# people own more expensive cars. Also this can be verified by the data.\n",
    "# The rest of the postalCodes show a similar 'right-skewed' distribution.\n",
    "\n",
    "plot_distribution(train_ex, \"price\",\n",
    "                  freq_postalCodes, \"postalCode\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion of the exploratory part\n",
    "As always mentioned in the plots descriptions, all of the numeric features have unrealistic values and many outliers. This has to be considered in the feature engineering part.\n",
    "\n",
    "The ordinal features labels are all understandable and do not need any further preparation. But the data itself is not equally distributed. Also are some strange connections discovered as for example between kilometers and price: Low kilometer cars have also the lowest median and mean prices. This is not reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 For supervised learning tasks, identify the target attribute(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have in our train set the prices for each vehicle, this is a supervised learning method. The training data that you enter into the algorithm contains the desired solutions, which is called a labels. In our case the label is the price. Because the price is a numerical value, it is predicted by a regression based on a set of features like (kilometer, powerPS, brand,...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots from lesson 1\n",
    "# Most of the cars have around 50 to 150 powerPS and a price of below 5000.\n",
    "chart = sns.jointplot(\n",
    "    'powerPS', 'price',\n",
    "    data=train_ex,\n",
    "    kind='hex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://lewtun.github.io/dslectures/lesson02_exploratory-data-analysis/\n",
    "# To get an deeper insight the kilometer an yearOfRegistration feature is included in a scatterplot. The setting of the \n",
    "# yearOfRegistration is done the same as in the exploratory part. In this chart in gets even more obvious how many\n",
    "# entries have none powerPS or a price of 0. Most of these entries have 150000 kilometers. It seems that there is a tendency\n",
    "# of cars with more kilometers have also more powerPS but also that the entries with lower kilometervalues have\n",
    "# have higher prices.\n",
    "\n",
    "fig = sns.scatterplot(\n",
    "    x=\"powerPS\",\n",
    "    y=\"price\",\n",
    "    data=train_ex,\n",
    "    alpha=0.4,\n",
    "    hue=\"kilometer\",\n",
    "    palette=\"coolwarm\",\n",
    "    size=train_ex[\"yearOfRegistration\"]\n",
    ")\n",
    "\n",
    "# place legend outside of figure\n",
    "fig.legend(loc=\"center left\", bbox_to_anchor=(1.01, 0.6), ncol=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-1.ipynb\n",
    "# The observation from the exploratory part is validated: The hybrid cars are the most expensive and have also the \n",
    "# highest single prices.\n",
    "\n",
    "# set plot size and font size\n",
    "figsize(14, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# violin plot to see descriptive statistics \n",
    "# and distribution\n",
    "# per fuelType\n",
    "f = sns.violinplot(data=train_ex,\n",
    "                   x=\"fuelType\",\n",
    "                   y=\"price\");\n",
    "\n",
    "f.set_xticklabels(f.get_xticklabels(),\n",
    "                  rotation=45);\n",
    "\n",
    "plt.title(\"Points from Different Tasters\",\n",
    "          size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.subplots() to create multiple plots\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n",
    "# put one plot on axis ax0\n",
    "sns.distplot(train_ex[\"powerPS\"], kde=True, ax=ax0)\n",
    "# put second plot on axis ax1\n",
    "sns.scatterplot(\"brand\", \"powerPS\", data=train_ex, ax=ax1)\n",
    "# tight_layout() fixes spacing between plots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.subplots() to create multiple plots\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n",
    "# put one plot on axis ax0\n",
    "sns.distplot(train_ex[\"kilometer\"], kde=True, ax=ax0)\n",
    "# put second plot on axis ax1\n",
    "sns.scatterplot(\"brand\", \"kilometer\", data=train_ex, ax=ax1)\n",
    "# tight_layout() fixes spacing between plots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.subplots() to create multiple plots\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n",
    "# put one plot on axis ax0\n",
    "sns.distplot(train_ex[\"kilometer\"], kde=True, ax=ax0)\n",
    "# put second plot on axis ax1\n",
    "sns.scatterplot(\"fuelType\", \"kilometer\", data=train_ex, ax=ax1)\n",
    "# tight_layout() fixes spacing between plots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.subplots() to create multiple plots\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(15\n",
    "                                                        , 7))\n",
    "# put one plot on axis ax0\n",
    "sns.distplot(train_ex[\"kilometer\"], kde=False, ax=ax0)\n",
    "# put second plot on axis ax1\n",
    "sns.scatterplot(\"yearOfRegistration\", \"brand\", data=train_ex, ax=ax1)\n",
    "# tight_layout() fixes spacing between plots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Study the correlations between attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots from lesson 1\n",
    "# Comparing the different integer features to each other to find some correlations\n",
    "# Shops a cap in kilometers at 150'000. It seems that one can not choose moore than this on the website.\n",
    "attributes = ['price', 'kilometer', 'powerPS', 'yearOfRegistration', 'monthOfRegistration', 'postalCode']\n",
    "sns.pairplot(train_ex[attributes].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots from lesson 1\n",
    "# Comparing the as relevant considered different original object features to each other to find some correlations\n",
    "# Shops a cap in kilometers at 150'000. It seems that one can not choose moore than this on the website.\n",
    "attributes = ['price', 'powerPS', 'abtest', 'vehicleType',\n",
    "              'gearbox', 'model', 'fuelType', 'brand', 'notRepairedDamage']\n",
    "sns.pairplot(train_ex[attributes].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dateCrawled, abtest, seller, offerType, and monthOfRegistratin are dropped because they are not expexted to give\n",
    "# further value to the model.\n",
    "corrs = train_ex.corr()\n",
    "corrs['price'].sort_values(ascending=False).sum(), corrs['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore the correlations of the categorical features as well, the df's NaN values are filled with the median for \n",
    "# a first try.\n",
    "train_ex_filled = filling_df(train_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex_filled.drop(['nrOfPictures'], axis=1, inplace=True); train_ex_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two plots provide a graphical overview of the correlations between the individual features.\n",
    "# The following two plots are derived from the following page:https://www.geeksforgeeks.org/exploring-correlation-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corrs = train_ex_filled.corr() \n",
    "  \n",
    "cg = sns.clustermap(corrs, cmap =\"YlGnBu\", linewidths = 0.1); \n",
    "plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation = 0);\n",
    "cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Identify the promising transformations you may want to apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following transformations seem to be reasonable and therfore promising:\n",
    "* powerPS+yearOfRegistration\n",
    "* powerPS+model\n",
    "* powerPS+name\n",
    "* powerPS+kilometer\n",
    "* powerPS+postalCode\n",
    "* kilometer+model\n",
    "* model+name\n",
    "* powerPS+yearOfRegistration+model\n",
    "* powerPS+yearOfRegistration+name\n",
    "* powerPS+model+name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Document what you have learned.\n",
    "The difference between the raw data and the adjusted data is huge. In all features some data had to be deleted to get a plausible result. For the feature \"powerPS\" the discrepancy was the biggest. We had values from 0 to about 2000ps. The cleaned up data covers a range of 10-500ps. This caused some data to be lost, but the plausible values without outliers allowed us to make more accurate predictions. \n",
    "Since the highest category is 150000 in the system, it is difficult to understand and edit this feature accurately. \n",
    "Furthermore we could not consider the data in the category 5000km as plausible. Because this category had the lowest average price, which didn't make much sense for us. \n",
    "This feature overstrained us in the data preparation. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Prepare the Data\n",
    "In the following subchapters the data is prepared in a way, that the algorithms can afterwards handle the data. For these parts the findings of the data exploratory part are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Data cleaning, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers of each features are removed, the missing values filled and attributes which do not provide useful informations for the task are dropped. To not manipulate the original dataset it is worked on a copy of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train.copy()\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the framing which excludes the unrealistic values of each rows\n",
    "\n",
    "def frame_df(df):\n",
    "    '''\n",
    "    Function applies the framing which excludes the unrealistic values of the dataset by dropping the \n",
    "    corresponding rows. Should be used just with the train dataset. If applied to the test dataset\n",
    "    rows will be missing.\n",
    "    '''\n",
    "    df = df.loc[(df.price < 50000)]\n",
    "    df = df.loc[(df.price > 10)]\n",
    "    df = df.loc[(df.powerPS < 500)]\n",
    "    df = df.loc[(df.powerPS > 10)]\n",
    "    df = df.loc[(df.kilometer < 150000)]\n",
    "    df = df.loc[(df.kilometer > 5000)]\n",
    "    df = df.loc[(df.yearOfRegistration < 2016)]\n",
    "    df = df.loc[(df.yearOfRegistration > 1995)]\n",
    "    df = df.loc[(df.monthOfRegistration > 0)]\n",
    "    df = df.loc[(df.postalCode < 98000)]\n",
    "    df = df.loc[(df.postalCode > 1000)]\n",
    "    \n",
    "    print(df.shape)    \n",
    "    print('Compared to the original dataset {} rows or {:.2f}% are dropped'\n",
    "          .format(\n",
    "          (train.shape[0]-df.shape[0]),\n",
    "          (100-df.shape[0]/train.shape[0]*100)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_framed = frame_df(train_clean)\n",
    "train_framed.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Looking at the most expensive cars after framing it.\n",
    "train_framed[train_framed.price > 49998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following funcion applies the findings of the data exploratory part.\n",
    "\n",
    "def prepare_df(df):\n",
    "    '''\n",
    "    Function cleans df corresponding to the findings of the data exploratory part.\n",
    "    '''\n",
    "    # dropping cols\n",
    "    cols_drop = ['dateCrawled',\n",
    "                 'abtest',\n",
    "                 'seller',\n",
    "                 'offerType',\n",
    "                 'monthOfRegistration',\n",
    "                 'nrOfPictures'\n",
    "                ]\n",
    "    \n",
    "    df = df.drop(columns = cols_drop)\n",
    "    \n",
    "    # OneHotEncode the low cardinality features\n",
    "    ## features to OneHotEncode\n",
    "    cols_ohe = ['notRepairedDamage',\n",
    "                'fuelType',\n",
    "                'gearbox',\n",
    "                'vehicleType',\n",
    "                'brand']\n",
    "    \n",
    "    ## OneHotEncoded df\n",
    "    df_encoded = pd.get_dummies(df[cols_ohe])\n",
    "    \n",
    "    ## Joining the orginal input dataset and the encoded one\n",
    "    df = pd.concat([df, df_encoded], axis=1) \n",
    "    \n",
    "    # Extracting dateparts into more useful parts\n",
    "    add_datepart(df, 'dateCreated')\n",
    "    add_datepart(df, 'lastSeen')\n",
    "    \n",
    "    # Converting strings to categories\n",
    "    convert_strings_to_categories(df)\n",
    "    \n",
    "    # Converting categories to numbers\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    # Appliying the mean instead of the median to the missing price values with 5000 kilometers    \n",
    "    mean_low_k = df.kilometer.mean()\n",
    "    df.kilometer.fillna(mean_low_k, inplace=True)\n",
    "    \n",
    "    # Filling rest of NaN's with median\n",
    "    median_df = df.median()\n",
    "    df.fillna(median_df, inplace=True)\n",
    "    \n",
    "    ## Dropping the encoded features\n",
    "    df = df.drop(columns = cols_ohe)  \n",
    "\n",
    "    df_cleaned = df\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = prepare_df(train_framed);\n",
    "train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check the nan values\n",
    "train_prepared.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some random samples\n",
    "train_prepared.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Feature engineering, where appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering following points are:\n",
    "\n",
    "* Discretize continuous features.\n",
    "* Decompose features (e.g. categorical, date/time, etc.).\n",
    "* Add promising transformations of features (e.g. log(x), squrt(x), x^2, etc.).\n",
    "* Aggregate features into promising new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating features into new features which are thought to be helpful.\n",
    "\n",
    "def aggregating_features(df):\n",
    "    '''\n",
    "    Function aggregates features based on the findings before.\n",
    "    '''\n",
    "    \n",
    "    df['powerPS+yearOfRegistration'] = df.powerPS + df.yearOfRegistration\n",
    "    df['powerPS+model'] = df.powerPS + df.model\n",
    "    df['powerPS+name'] = df.powerPS + df.name\n",
    "    df['powerPS+kilometer'] = df.powerPS + df.kilometer\n",
    "    df['powerPS+postalCode'] = df.powerPS + df.postalCode\n",
    "    df['kilometer+model'] = df.kilometer + df.model\n",
    "    df['model+name'] = df.model + df.name\n",
    "    df['powerPS+yearOfRegistration+model'] = df.powerPS + df.yearOfRegistration + df.model\n",
    "    df['powerPS+yearOfRegistration+name'] = df.powerPS + df.yearOfRegistration + df.name\n",
    "    df['powerPS+model+name'] = df.powerPS + df.model + df.name\n",
    "    \n",
    "    aggregated_df = df\n",
    "    \n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aggregated = aggregating_features(train_prepared)\n",
    "train_aggregated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Short-List Promising Models\n",
    "In this part are different models trained and evaluated. Also the individual parts are contained here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Training many quick and dirty models from different categories and comparing their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models = train_aggregated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_models.drop('price', axis=1)\n",
    "y = train_models.price\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "print('Train, validation split:')\n",
    "print(f'{len(X_train)} train rows\\n{len(X_valid)} validation rows\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created baseline model function to compare the feature engineering development\n",
    "def baseline_model_score2(df):\n",
    "    '''\n",
    "    Baseline model of simple RandomForestRegressor to measure the impact of the feature engineering steps\n",
    "    '''\n",
    "    model = RandomForestRegressor()\n",
    "    model = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=69)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Metrics:')\n",
    "    print_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_score2(train_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the RMSE of the following untuned models to find the best model for the problem\n",
    "regressors1 = [\n",
    "    RandomForestRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    AdaBoostRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    LGBMRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    IsolationForest(),\n",
    "    DecisionTreeRegressor(),\n",
    "    HistGradientBoostingRegressor(),\n",
    "    XGBRegressor(),\n",
    "    ElasticNet()\n",
    "    ]\n",
    "\n",
    "log_cols = [\"Regressor\", \"RMSE\"]\n",
    "log \t = pd.DataFrame(columns=log_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for rgrs in regressors1:\n",
    "    name = rgrs.__class__.__name__\n",
    "    rgrs.fit(X_train, y_train)\n",
    "    train_predictions = rgrs.predict(X_valid)    \n",
    "    RMSE = rmse(y_valid, train_predictions)\n",
    "    log = log.append({'Regressor':name, 'RMSE':RMSE}, ignore_index=True)\n",
    "\n",
    "plt.title('Regressor RMSE')\n",
    "plt.xlabel('RMSE')\n",
    "sns.barplot(x='RMSE', y='Regressor', data=log.sort_values(ascending=True, by='RMSE'), color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part just the models with the best 5 models are taken into account. (Adopted part of https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('best_random_rf', 'rb')\n",
    "# best_random_rf = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best hyperparameters is looked for with the RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 200, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Creating the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First creating the base model to tune\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 10,\n",
    "                               cv = 3,\n",
    "                               verbose=5,\n",
    "                               random_state=69, \n",
    "                               n_jobs = -1)\n",
    "# Fitting the random search model\n",
    "%time rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(best_random_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_rf = rf_random.best_estimator_\n",
    "%time random_rf_score = print_scores(best_random_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('best_random_rf', 'wb')\n",
    "pickle.dump(best_random_rf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking with randomized grid search for some models for best tuning parameters and comparing the performance of VotingRegressor to StackingRegressor - Lappert Michael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides to the RandomForestRegressor to the 4 best models of the model evaluation part a hyperparamter-tuning is applied.\n",
    "#### ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "pickle_in = open('best_random_et', 'rb')\n",
    "best_random_et = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best hyperparameters is looked for with the RandomizedSearchCV\n",
    "\n",
    "# Number of trees in forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8, 16]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Creating the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First creating the base model to tune\n",
    "\n",
    "et = ExtraTreesRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "et_random = RandomizedSearchCV(estimator = et, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 10,\n",
    "                               cv = 3,\n",
    "                               verbose=5,\n",
    "                               random_state=69, \n",
    "                               n_jobs = -1)\n",
    "# Fitting the random search model\n",
    "%time et_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_et = et_random.best_estimator_\n",
    "%time random_et_score = print_scores(best_random_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('best_random_et', 'wb')\n",
    "pickle.dump(best_random_et, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('best_random_xgb', 'rb')\n",
    "# best_random_xgb = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best hyperparameters is looked for with the RandomizedSearchCV\n",
    "\n",
    "\n",
    "nthread = [3, 4, 5]\n",
    "objective = ['reg:squaredlogerror']\n",
    "learning_rate = [0.01, 0.03, 0.05, 0.07, 0.1]\n",
    "max_depth = [1, 3, 5, 7]\n",
    "min_child_weight = [2, 4, 6]\n",
    "silent = [1]\n",
    "subsample = [0.6, 0.7, 0.8, 0.9]\n",
    "colsample_bytree = [0.5, 0.7, 0.9]\n",
    "n_estimators = [1000]\n",
    "    \n",
    "\n",
    "\n",
    "# Creating the random grid\n",
    "random_grid = {'nthread':nthread,\n",
    "              'objective':objective,\n",
    "              'learning_rate':learning_rate,\n",
    "              'max_depth':max_depth,\n",
    "              'min_child_weight':min_child_weight,\n",
    "              'silent':silent,\n",
    "              'subsample':subsample,\n",
    "              'colsample_bytree':colsample_bytree,\n",
    "              'n_estimators':n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First creating the base model to tune\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across different combinations, and use all available cores\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 10,\n",
    "                               cv = 3,\n",
    "                               verbose=5,\n",
    "                               random_state=69, \n",
    "                               n_jobs = -1)\n",
    "# Fitting the random search model\n",
    "%time xgb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_xgb = xgb_random.best_estimator_\n",
    "%time random_xgb_score = print_scores(best_random_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('best_random_xgb', 'wb')\n",
    "pickle.dump(best_random_xgb, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistGradiantBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('best_random_hgb', 'rb')\n",
    "# best_random_hgb = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best hyperparameters is looked for with the RandomizedSearchCV\n",
    "\n",
    "\n",
    "learning_rate = [0.05, 0.1, 0.01]\n",
    "max_iter = [1000, 1500, 2000]\n",
    "max_leaf_nodes = [2, 4, 8, 16, 32, 64, 128]\n",
    "max_depth = [25, 50, 75]\n",
    "min_samples_leaf = [5, 10, 20, 30, 35]\n",
    "scoring = ['reg:squaredlogerror']\n",
    "l2_regularization = [1.5]\n",
    "#n_estimators = [1000]\n",
    "    \n",
    "\n",
    "\n",
    "# Creating the random grid\n",
    "random_grid = {'learning_rate':learning_rate,\n",
    "              'max_iter':max_iter,\n",
    "              'max_leaf_nodes':max_leaf_nodes,\n",
    "              'max_depth':max_depth,\n",
    "              'min_samples_leaf':min_samples_leaf,\n",
    "              'scoring':scoring,\n",
    "               'l2_regularization':l2_regularization\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First creating the base model to tune\n",
    "\n",
    "hgb =  HistGradientBoostingRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across different combinations, and use all available cores\n",
    "hgb_random = RandomizedSearchCV(estimator = hgb, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 10,\n",
    "                               cv = 3,\n",
    "                               verbose=5,\n",
    "                               random_state=69, \n",
    "                               n_jobs = -1)\n",
    "# Fitting the random search model\n",
    "%time hgb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_hgb = hgb_random.best_estimator_\n",
    "%time random_hgb_score = print_scores(best_random_hgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('best_random_hgb', 'wb')\n",
    "pickle.dump(best_random_hgb, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('best_random_lgbm', 'rb')\n",
    "# best_random_lgbm = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best hyperparameters is looked for with the RandomizedSearchCV\n",
    "\n",
    "num_leaves =list(range(8, 120, 4))\n",
    "min_data_in_leaf = [5, 10, 20, 40, 60, 100]\n",
    "max_depth = [3, 4, 5, 6, 8, 12, 16, -1]\n",
    "learning_rate = [0.2, 0.15, 0.1, 0.05, 0.01, 0.005]\n",
    "bagging_freq = [1, 2, 3, 4, 5, 6, 7]\n",
    "bagging_fraction = np.linspace(0.3, 0.95, 10)\n",
    "reg_alpha = np.linspace(0.1, 0.95, 10)\n",
    "reg_lambda = np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "\n",
    "\n",
    "random_grid = {'num_leaves': num_leaves,\n",
    "               'min_data_in_leaf': min_data_in_leaf,\n",
    "               'max_depth': max_depth,\n",
    "               'learning_rate': learning_rate,\n",
    "               'bagging_freq': bagging_freq,\n",
    "               'bagging_fraction': bagging_fraction,\n",
    "               'reg_alpha': reg_alpha,\n",
    "               'reg_lambda': reg_lambda\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First creating the base model to tune\n",
    "\n",
    "lgbm =  LGBMRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across different combinations, and use all available cores\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm, \n",
    "                                 param_distributions = random_grid,\n",
    "                                 n_iter = 30,\n",
    "                                 cv = 3,\n",
    "                                 verbose=5,\n",
    "                                 random_state=69, \n",
    "                                 n_jobs = -1)\n",
    "# Fitting the random search model\n",
    "%time lgbm_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_lgbm = lgbm_random.best_estimator_\n",
    "%time random_lgbm_score = print_scores(best_random_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('best_random_lgbm', 'wb')\n",
    "pickle.dump(best_random_lgbm, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingRegressor\n",
    "Here are the models with the highest RMSE score in the randomized grid search part ensembled. This is done with the VotingRegressor of sklearn. The VotingRegressor combines the given machine learning regressors and returns the average predicted value. This can be useful to balance out the individual weaknesses of otherwise eaqually well performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('VotingRegressor', 'rb')\n",
    "# votreg = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "train_models = train_aggregated.copy()\n",
    "\n",
    "X = train_models.drop('price', axis=1)\n",
    "y = train_models.price\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "print('Train, validation split:')\n",
    "print(f'{len(X_train)} train rows\\n{len(X_valid)} validation rows\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votreg = VotingRegressor(estimators=[('lgbm', best_random_lgbm),\n",
    "                                     ('hgb', best_random_hgb),\n",
    "                                     ('et', best_random_et)])\n",
    "\n",
    "%time votreg = votreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(votreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('VotingRegressor', 'wb')\n",
    "pickle.dump(votreg, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the VotingRegressors estimators prediction as well as the VotingRegressors prediction itself are visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py\n",
    "xt = X_train[:20]\n",
    "\n",
    "pred1 = best_random_lgbm.predict(xt)\n",
    "pred2 = best_random_hgb.predict(xt)\n",
    "pred3 = best_random_et.predict(xt)\n",
    "pred4 = votreg.predict(xt)\n",
    "\n",
    "plt.figure();\n",
    "plt.figure(figsize=(15,8));\n",
    "plt.plot(pred1, 'gd', label='LGBMRegressor');\n",
    "plt.plot(pred2, 'b^', label='HistGradientBoostinRegressor');\n",
    "plt.plot(pred3, 'ys', label='ExtraTreesRegressor');\n",
    "plt.plot(pred4, 'r*', ms=10, label='VotingRegressor');\n",
    "\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
    "                labelbottom=False);\n",
    "plt.ylabel('predicted', fontsize=15);\n",
    "plt.xlabel('training samples', fontsize = 15);\n",
    "plt.legend(loc=\"best\", fontsize=15);\n",
    "plt.title('Regressor predictions and their average', fontsize = 20);\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StackingRegressor\n",
    "In the following cells is the performance of the VotingRegressor compared to the StackingRegressor. With the stecked generalization, which is perfomed with the StackingRegressor, the idea is to reduce the biases of the different models. This is done by stacking the predictions of each individual estimator and used as input to a final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below code and skip next 2 cells in case the noteboook ran already once on this computer.\n",
    "# pickle_in = open('StackingRegressor', 'rb')\n",
    "# stackreg = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [('lgbm', best_random_lgbm),\n",
    "              ('hgb', best_random_hgb),\n",
    "              ('et', best_random_et)]\n",
    "\n",
    "stackreg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=best_random_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time stackreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(stackreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py\n",
    "xt = X_train[:20]\n",
    "\n",
    "pred1 = best_random_lgbm.predict(xt)\n",
    "pred2 = best_random_hgb.predict(xt)\n",
    "pred3 = best_random_et.predict(xt)\n",
    "pred4 = best_random_rf.predict(xt)\n",
    "pred5 = stackreg.predict(xt)\n",
    "\n",
    "plt.figure();\n",
    "plt.figure(figsize=(15,8));\n",
    "plt.plot(pred1, 'gd', label='LGBMRegressor');\n",
    "plt.plot(pred2, 'b^', label='HistGradientBoostinRegressor');\n",
    "plt.plot(pred3, 'ys', label='ExtraTreesRegressor');\n",
    "plt.plot(pred4, 'co', label='RandomforestRegressor');\n",
    "plt.plot(pred4, 'r*', ms=10, label='StackingRegressor');\n",
    "\n",
    "\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False,\n",
    "                labelbottom=False);\n",
    "plt.ylabel('predicted', fontsize=15);\n",
    "plt.xlabel('training samples', fontsize = 15);\n",
    "plt.legend(loc=\"best\", fontsize=15);\n",
    "plt.title('Regressor predictions and their average', fontsize = 20);\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('StackingRegressor', 'wb')\n",
    "pickle.dump(stackreg, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear Regression Model - Bischof Tobias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following model is based on the structure of the following two pages:https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f\n",
    "                                                                        #:https://towardsdatascience.com/introduction-to-linear-regression-141cde7a46b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LR = train_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the correlation of the different features is shown. Since powerPS has the highest correlation, \n",
    "#I decided to use this feature to create a LR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corrs = train_LR.corr()\n",
    "corrs['price'].sort_values(ascending=False).sum(), corrs['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This plot shows us that the raw data is useless for a prediction based on the feature powerPS and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(train_LR['powerPS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(train_LR['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphical representation of the two features with cleaned values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LR.plot(x='price', y='powerPS', style='o')  \n",
    "plt.title('price vs powerPS')  \n",
    "plt.xlabel('price')  \n",
    "plt.ylabel('powerPS')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step is to assign both features to an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_LR['powerPS'].values.reshape(-1,1)\n",
    "y = train_LR['price'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is divided into a training set and a test set in a ratio of 80 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After we have divided the data into training and test sets, the algorithm is trained. To do this, we have to import the class LinearRegression, instantiate it and call the method fit() together with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) #training the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you can see the value of the intercept and slope calculated by the linear regression algorithm for our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrieve the intercept:\n",
    "print(regressor.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the algorithm is trained, a prediction is now made. For this purpose we will use our test data and see how accurately our algorithm predicts the percentage result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the next two plots the predicted values are compared with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(50)\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot with a trend line with the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test,  color='gray')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following result, cannot make such an accurate prediction. Because the model is based on only one feature(powerPS). \n",
    "#A multiple LR would certainly be more accurate since the prediction is based on more than one feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of only one numerical feature, additional features with a high correlation were added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is also divided into \"attributes\" and \"labels\". The X-variable contains the 3 features and the y-variable contains labels (price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_LR[['kilometer', 'yearOfRegistration', 'powerPS']].values\n",
    "y = train_LR['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we create an overview of the average prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(train_LR['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we split 80% of the data for the training set, while 20% of the data for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference between the actual value and the predicted value is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The additional features brought better results. However, negative price predictions are unrealistic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we see a significant improvement to the model with only one feature. \n",
    "#Because the algorithm now combines several values and thus gets more information and the predictions are also more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### MultiLayerPerception - Vogt Tobias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model is based on the structure of the following two pages: https://www.pluralsight.com/guides/machine-learning-neural-networks-scikit-learn -> but MLPClassifier changend to MLPRegressor \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_keep = ['price', 'powerPS', 'kilometer', 'yearOfRegistration']\n",
    "train_M = train_models[cols_keep]\n",
    "train_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  train_M\n",
    "print(df.shape)\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['price'] \n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(f'{len(X_train)} train rows + {len(X_valid)} valid rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "regr =  MLPRegressor(hidden_layer_sizes=(100,100), alpha=0.001, learning_rate_init=0.01,\n",
    "                     power_t=0.5, max_iter=500, shuffle=True,\n",
    "                     random_state=None, tol=0.0001, verbose=False, warm_start=False,\n",
    "                     validation_fraction=0.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Analyzing the most significant variables for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e\n",
    "\n",
    "def drop_col_feat_imp(model, X_train, y_train, random_state = 69):\n",
    "    \n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(X_train, y_train)\n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "    \n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "    \n",
    "    importances_df = imp_df(X_train.columns, importances)\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time drop_col_feat_imp(best_random_rf, X_train, y_train, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Analze the types of errors the models make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What data would a human have used to avoid these errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_error(fitted_model, X, y):\n",
    "    \"\"\"\n",
    "    A utility function to visualise the prediction errors of regression models.\n",
    "    \n",
    "    Args:\n",
    "        fitted_model: A scikit-learn regression model.\n",
    "        X: The feature matrix to generate predictions on.\n",
    "        y: The target vector compare the predictions against.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.scatterplot(y, y_pred)\n",
    "    sns.lineplot([y.min(), y.max()], [y.min(), y.max()], lw=2, color=\"r\")\n",
    "    plt.xlabel(\"Actual Median Car Price\")\n",
    "    plt.ylabel(\"Predicted Median Car Price\")\n",
    "    plt.title(f\"Prediction Error for {model.__class__.__name__}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_error(best_random_rf, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(fitted_model, X, y):\n",
    "    '''\n",
    "    A utility function to visualise the residuals of regression models.\n",
    "    \n",
    "    Args:\n",
    "        fitted_model: A scikit-learn regression model.\n",
    "        X: The feature matrix to generate predictions on.\n",
    "        y: The target vector compare the predictions against.   \n",
    "    '''\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    sns.residplot(y_pred, y - y_pred)\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.xlabel('Predicted Median Car Price')\n",
    "    plt.title(f'Residuals for {model.__class__.__name__}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(best_random_rf, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Model interpretability Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([t.predict(X_valid) for t in best_random_rf.estimators_])\n",
    "# calculate mean and standard deviation for single observation\n",
    "np.mean(preds[:,0]), np.std(preds[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='kilometer', data=train_models);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure \n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1, figsize=(12,7), sharex=True)\n",
    "\n",
    "# plot ground truth\n",
    "train_models.plot('kilometer', 'price', 'barh', ax=ax0)\n",
    "# put legend outside plot\n",
    "ax0.legend(loc='upper left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "# plot preds\n",
    "train_models.plot('kilometer', 'preds_mean', 'barh', xerr='preds_std', alpha=0.6, ax=ax1)\n",
    "# put legend outside plot\n",
    "ax1.legend(loc='upper left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = test.copy()\n",
    "test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepared = prepare_df(test_sub)\n",
    "test_aggregated = aggregating_features(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_random_lgbm.predict(test_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission['Id'].to_frame()\n",
    "submission['Predicted'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('your_path', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Solution presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Documentation of what is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data; \n",
    "* here from Kaggle\n",
    "### Explore the data; \n",
    "* looking randomly some data\n",
    "* searching the missing values\n",
    "* exploring the number of unique labels of the object features\n",
    "* a lot of plots like number of cars by brand\n",
    "### Prepare the Data;\n",
    "* applying the framing which excludes the unrealistic values of each rows\n",
    "* dropping cols\n",
    "* appliying the mean instead of the median to the missing price values with 500 kilometers   \n",
    "* filling the NaNâs with median\n",
    "* aggregating features into new features which are thought to be helpful\n",
    "### Evaluate models\n",
    "* evaluating performances of many different models such as RandomForestRegressor, LGBMRegressor...\n",
    "* fine-tuning of different models in individual parts\n",
    "* combining best scoring models from the evaluation\n",
    "* looking at the prediction errors the RandomForestRegressor makes\n",
    "* interpreting the results of the RandomForestRegressor\n",
    "* predicting as last model step the test data and submitted it several times to the kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Reflection of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_presentation = train_aggregated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of PS in relation to the price\n",
    "train_presentation = train_presentation.loc[(train_presentation.powerPS < 1000)]\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_presentation, 'powerPS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The year of registration in realtion to the price\n",
    "train_presentation = train_presentation.loc[(train_presentation.yearOfRegistration<2016)]\n",
    "train_presentation = train_presentation.loc[(train_presentation.yearOfRegistration>1930)]\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_presentation, 'yearOfRegistration');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of kilometers in realtion to the price\n",
    "figsize(8, 6)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plot_histogram(train_presentation, 'kilometer');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Explanation of achieving the business objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business objective was to build a machine learning model, which predicts the selling price of a car on basis of a given dataset. It can be said, that this objective is achieved. The created model achieves an Roor mean squared error of around 4000 on the test data.\n",
    "The model could be improved with the following points:\n",
    "\n",
    "**Feature engineering**\n",
    "* The whole data set should be normalized.\n",
    "* The name should be extracted and analyzed through Natural language processing (nlp).\n",
    "* The evaluation \"median price\" / \"kilometer\" does not yet make complete sense. Because the fewer kilometers a car has, the higher the price should be. However, the price is lowest for vehicles with 5000 kilometres. Therefore we conclude that we have not yet fully decomposed this feature to understand all the details.\n",
    "* It is not found the meaning of every feature as e.g. abtest. For deeper understanding of the dataset it would be helpful to fully understand what data one is working with.\n",
    "\n",
    "**ML Model**\n",
    "* It should be taken care of that the model does not overfit the training data\n",
    "* The random grid search could be extended to more iterations to find possible better combinations\n",
    "* Instead of a random grid search a 'non randomized' grid search could be applied to not miss any useful combination\n",
    "* Additional feature engineering rounds could be done after the best model was selected\n",
    "\n",
    "Besides the mentioned aspects, we are satisfied with our work. We believe that we were able to apply the theoretical contents of the lessons in this practical example and can therefore look back on a successful and exciting project. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
